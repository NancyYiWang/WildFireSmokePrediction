{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN0ZjCgwG1vOYOnN1f0ZNPd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NancyYiWang/WildFireSmokePrediction/blob/main/PredictModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUte43UNdC7t",
        "outputId": "3bf9d4d5-76f5-40e6-8a4c-8e4b4791d08f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LSTM, Dense, Flatten, TimeDistributed, Concatenate\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYWWXnnvfsvA",
        "outputId": "55f471e0-07e4-46c6-f148-e2af37f23192"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.12.14)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.8)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.1)\n",
            "Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build training data from GOES .nc files\n",
        "\n",
        "goes_dir = \"/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001\"\n",
        "smoke_output_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\"\n",
        "temp_output_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\"\n",
        "\n",
        "smoke_variables = [\n",
        "    \"MVFR_Fog_Prob\",\n",
        "    \"IFR_Fog_Prob\",\n",
        "    \"LIFR_Fog_Prob\",\n",
        "    \"Fog_Depth\",\n",
        "]\n",
        "temp_variables = [\n",
        "    \"Sfc_Temp_Bias\",\n",
        "]\n",
        "\n",
        "def extract_timestamp_from_filename(filename):\n",
        "\n",
        "    try:\n",
        "        timestamp = filename.split('_s')[1][:12]\n",
        "        return timestamp\n",
        "    except IndexError:\n",
        "        print(f\"Error extracting timestamp from {filename}\")\n",
        "        return None\n",
        "\n",
        "def filter_first_file_per_hour(nc_files):\n",
        "\n",
        "    hourly_files = {}\n",
        "    for nc_file in nc_files:\n",
        "        timestamp = extract_timestamp_from_filename(nc_file)\n",
        "        if not timestamp:\n",
        "            continue\n",
        "        hour = timestamp[8:10]\n",
        "        if hour not in hourly_files:\n",
        "            hourly_files[hour] = nc_file\n",
        "    return list(hourly_files.values())\n",
        "\n",
        "def process_goes_files(file_list, variables):\n",
        "\n",
        "    datasets = []\n",
        "    for file in file_list:\n",
        "        try:\n",
        "            with xr.open_dataset(file) as ds:\n",
        "                selected_vars = {var: ds[var].load() for var in variables if var in ds.variables}\n",
        "                if selected_vars:\n",
        "                    datasets.append(xr.Dataset(selected_vars))\n",
        "                else:\n",
        "                    print(f\"Warning: No matching variables found in {file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file}: {e}\")\n",
        "\n",
        "    if not datasets:\n",
        "        raise ValueError(\"No datasets were created. Please check the file list and variables.\")\n",
        "\n",
        "    combined_dataset = xr.concat(datasets, dim=\"time\")\n",
        "    return combined_dataset\n",
        "\n",
        "def main():\n",
        "\n",
        "    all_files = sorted([f for f in os.listdir(goes_dir) if f.endswith(\".nc\")])\n",
        "\n",
        "    selected_files = filter_first_file_per_hour(all_files)\n",
        "    selected_files = [os.path.join(goes_dir, f) for f in selected_files]\n",
        "    print(f\"GOES files to be used: {selected_files}\")\n",
        "\n",
        "    smoke_data = process_goes_files(selected_files, smoke_variables)\n",
        "    smoke_data.to_netcdf(smoke_output_file)\n",
        "    print(f\"Smoke-related data has been saved to: {smoke_output_file}\")\n",
        "\n",
        "    temp_data = process_goes_files(selected_files, temp_variables)\n",
        "    temp_data.to_netcdf(temp_output_file)\n",
        "    print(f\"Temperature-related data has been saved to: {temp_output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkwelbVlf4Yj",
        "outputId": "0d1c14ea-ca15-4396-b8c2-c1bd983d1fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOES files to be used: ['/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010001179_e202406010003552_c202406010005019.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010101179_e202406010103552_c202406010104599.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010201180_e202406010203553_c202406010204482.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010301180_e202406010303553_c202406010304596.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010401180_e202406010403553_c202406010404397.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010501180_e202406010503553_c202406010504465.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010601180_e202406010603553_c202406010605063.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010701180_e202406010703553_c202406010704577.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010801180_e202406010803553_c202406010804449.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010901180_e202406010903553_c202406010904586.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011001180_e202406011003553_c202406011004398.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011101180_e202406011103553_c202406011104571.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011201181_e202406011203553_c202406011205051.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011301181_e202406011303554_c202406011304478.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011401181_e202406011403554_c202406011404586.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011501181_e202406011503554_c202406011504433.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011601181_e202406011603554_c202406011604419.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011701181_e202406011703554_c202406011704572.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011801181_e202406011803554_c202406011805035.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011901181_e202406011903554_c202406011904541.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012001181_e202406012003554_c202406012004503.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012101181_e202406012103554_c202406012104439.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012201182_e202406012203554_c202406012204452.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012301182_e202406012303555_c202406012304417.nc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_nc_file(nc_file):\n",
        "\n",
        "    with xr.open_dataset(nc_file) as ds:\n",
        "        print(f\"Inspecting file: {nc_file}\")\n",
        "        print(\"\\nVariables and Dimensions:\")\n",
        "        for var in ds.variables:\n",
        "            print(f\"{var}: {ds[var].dims} {ds[var].shape}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "inspect_nc_file(smoke_output_file)\n",
        "inspect_nc_file(temp_output_file)\n",
        "\n",
        "def inspect_lat_lon_ranges(nc_file):\n",
        "    with xr.open_dataset(nc_file) as ds:\n",
        "        lat = ds['Latitude'].values\n",
        "        lon = ds['Longitude'].values\n",
        "        lat_min, lat_max = lat.min(), lat.max()\n",
        "        lon_min, lon_max = lon.min(), lon.max()\n",
        "\n",
        "    print(f\"File: {nc_file}\")\n",
        "    print(f\"Latitude range: {lat_min} to {lat_max}\")\n",
        "    print(f\"Longitude range: {lon_min} to {lon_max}\\n\")\n",
        "\n",
        "inspect_lat_lon_ranges(smoke_output_file)\n",
        "inspect_lat_lon_ranges(temp_output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ36xNgb0mmL",
        "outputId": "0ef8df6d-bf14-4516-a015-fee39515bf34"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting file: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\n",
            "\n",
            "Variables and Dimensions:\n",
            "Latitude: ('Rows', 'Columns') (1500, 2500)\n",
            "Longitude: ('Rows', 'Columns') (1500, 2500)\n",
            "MVFR_Fog_Prob: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "IFR_Fog_Prob: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "LIFR_Fog_Prob: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "Fog_Depth: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "\n",
            "\n",
            "Inspecting file: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\n",
            "\n",
            "Variables and Dimensions:\n",
            "Latitude: ('Rows', 'Columns') (1500, 2500)\n",
            "Longitude: ('Rows', 'Columns') (1500, 2500)\n",
            "Sfc_Temp_Bias: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "\n",
            "\n",
            "File: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\n",
            "Latitude range: 14.571340560913086 to 53.500064849853516\n",
            "Longitude range: -179.999267578125 to 179.99940490722656\n",
            "\n",
            "File: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\n",
            "Latitude range: 14.571340560913086 to 53.500064849853516\n",
            "Longitude range: -179.999267578125 to 179.99940490722656\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_index_from_lat_lon(ds, lat_range, lon_range):\n",
        "\n",
        "    lat = ds['Latitude'].values\n",
        "    lon = ds['Longitude'].values\n",
        "\n",
        "    row_start = np.argmin(np.abs(lat[:, 0] - lat_range[1]))\n",
        "    row_end = np.argmin(np.abs(lat[:, 0] - lat_range[0]))\n",
        "\n",
        "    col_start = np.argmin(np.abs(lon[0, :] - lon_range[0]))\n",
        "    col_end = np.argmin(np.abs(lon[0, :] - lon_range[1]))\n",
        "\n",
        "    return slice(row_start, row_end + 1), slice(col_start, col_end + 1)\n",
        "\n",
        "\n",
        "def subset_nc_file(nc_file, lat_range, lon_range):\n",
        "\n",
        "    with xr.open_dataset(nc_file) as ds:\n",
        "        row_slice, col_slice = get_index_from_lat_lon(ds, lat_range, lon_range)\n",
        "        print(f\"Row slice: {row_slice.start} to {row_slice.stop - 1}\")\n",
        "        print(f\"Column slice: {col_slice.start} to {col_slice.stop - 1}\")\n",
        "\n",
        "        ds_subset = ds.isel(Rows=row_slice, Columns=col_slice)\n",
        "        return ds_subset\n",
        "\n",
        "lat_range = [49.5, 52.5]\n",
        "lon_range = [-116.0, -112.0]\n",
        "\n",
        "smoke_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\"\n",
        "temp_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\"\n",
        "\n",
        "smoke_data_subset = subset_nc_file(smoke_file, lat_range, lon_range)\n",
        "print(f\"Subsetted smoke data dimensions:\\n{smoke_data_subset.dims}\\n\")\n",
        "\n",
        "temp_data_subset = subset_nc_file(temp_file, lat_range, lon_range)\n",
        "print(f\"Subsetted temperature data dimensions:\\n{temp_data_subset.dims}\\n\")\n",
        "\n",
        "output_smoke_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke_subset.nc\"\n",
        "output_temp_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp_subset.nc\"\n",
        "\n",
        "smoke_data_subset.to_netcdf(output_smoke_file)\n",
        "print(f\"Subsetted smoke data saved to: {output_smoke_file}\")\n",
        "\n",
        "temp_data_subset.to_netcdf(output_temp_file)\n",
        "print(f\"Subsetted temperature data saved to: {output_temp_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H0k5oc51h2E",
        "outputId": "20be74c7-d2d0-4c85-adba-959f374b037f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row slice: 22 to 94\n",
            "Column slice: 1909 to 2021\n",
            "Subsetted smoke data dimensions:\n",
            "FrozenMappingWarningOnValuesAccess({'Rows': 73, 'Columns': 113, 'time': 24})\n",
            "\n",
            "Row slice: 22 to 94\n",
            "Column slice: 1909 to 2021\n",
            "Subsetted temperature data dimensions:\n",
            "FrozenMappingWarningOnValuesAccess({'Rows': 73, 'Columns': 113, 'time': 24})\n",
            "\n",
            "Subsetted smoke data saved to: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke_subset.nc\n",
            "Subsetted temperature data saved to: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp_subset.nc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weather_data(nc_files, time_range):\n",
        "    weather_features = []\n",
        "    for file in nc_files:\n",
        "        with xr.open_dataset(file) as ds:\n",
        "            ds_filtered = ds.sel(time=slice(*time_range))\n",
        "            feature = ds_filtered.to_array().values\n",
        "            weather_features.append(feature)\n",
        "    return np.stack(weather_features, axis=-1)\n",
        "\n",
        "\n",
        "def load_terrain_data(terrain_file, downscale_factor=4):\n",
        "    with rasterio.open(terrain_file) as src:\n",
        "        terrain = src.read(\n",
        "            1, out_shape=(\n",
        "                int(src.height // downscale_factor),\n",
        "                int(src.width // downscale_factor)\n",
        "            )\n",
        "        )\n",
        "    terrain = terrain / np.max(terrain)\n",
        "    return terrain\n",
        "\n",
        "def load_smoke_and_temp(smoke_file, temp_file):\n",
        "\n",
        "    with xr.open_dataset(smoke_file) as smoke_ds:\n",
        "        smoke_data = smoke_ds.to_array().values\n",
        "\n",
        "    with xr.open_dataset(temp_file) as temp_ds:\n",
        "        temp_data = temp_ds.to_array().values\n",
        "\n",
        "    time_ids = np.arange(1967184, 1967208)\n",
        "\n",
        "    return smoke_data, temp_data, time_ids\n",
        "\n",
        "def build_model(input_shape_smoke, input_shape_weather, input_shape_terrain):\n",
        "    # Input for smoke data (CNN)\n",
        "    smoke_input = Input(shape=input_shape_smoke, name=\"Smoke_Input\")\n",
        "    x = TimeDistributed(Conv2D(4, (3, 3), activation=\"relu\", padding=\"same\"))(smoke_input)\n",
        "    x = TimeDistributed(Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\"))(x)\n",
        "    x = TimeDistributed(Flatten())(x)  # Shape: (time_steps, flattened_features)\n",
        "\n",
        "    # Input for weather data (LSTM)\n",
        "    weather_input = Input(shape=input_shape_weather, name=\"Weather_Input\")\n",
        "    w = LSTM(16, return_sequences=True)(weather_input)\n",
        "    w = LSTM(16)(w)\n",
        "\n",
        "    # Input for terrain data (Dense)\n",
        "    terrain_input = Input(shape=input_shape_terrain, name=\"Terrain_Input\")\n",
        "    t = Dense(64, activation=\"relu\")(terrain_input)  # Shape: (64,)\n",
        "\n",
        "    # Combine all inputs\n",
        "    combined = Concatenate()([Flatten()(x), w, t])  # Shape: (combined_features,)\n",
        "\n",
        "    # Output layer\n",
        "    output_size = input_shape_smoke[1] * input_shape_smoke[2] * input_shape_smoke[3]\n",
        "    out = Dense(output_size, activation=\"sigmoid\")(combined)  # Flattened output\n",
        "    out = tf.keras.layers.Reshape(target_shape=input_shape_smoke[1:])(out)  # Reshape to (height, width, channels)\n",
        "\n",
        "    # Define model\n",
        "    model = Model(inputs=[smoke_input, weather_input, terrain_input], outputs=out)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KCGOXEiOVddU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File Directories\n",
        "nc_files = [\"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/vwnd.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/air.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/hgt.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/omega.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/rhum.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/uwnd.2024.nc\"]\n",
        "terrain_file = \"/content/drive/My Drive/WildFire/DATA/Terrain/terrain_broad_calgary.tiff\"\n",
        "smoke_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke_subset.nc\"\n",
        "temp_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp_subset.nc\"\n",
        "\n",
        "# Processing files\n",
        "time_range = (\"2024-06-01T00:00:00\", \"2024-06-01T23:00:00\")\n",
        "\n",
        "weather_data = load_weather_data(nc_files, time_range)\n",
        "terrain_data = load_terrain_data(terrain_file)\n",
        "smoke_data, temp_data, time_ids = load_smoke_and_temp(smoke_file, temp_file)\n",
        "\n",
        "# Define input datashape\n",
        "time_steps = smoke_data.shape[0]\n",
        "input_shape_smoke = (time_steps, smoke_data.shape[1], smoke_data.shape[2], 1)\n",
        "input_shape_weather = (time_steps, weather_data.shape[-1])\n",
        "input_shape_terrain = (terrain_data.size,)\n",
        "\n",
        "# Train model\n",
        "model = build_model(input_shape_smoke, input_shape_weather, input_shape_terrain)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "x_smoke = smoke_data[:, :-1, :, :, np.newaxis]  # Cut off the last time_step to use the data as input\n",
        "y_smoke = smoke_data[:, 1:, :, :, np.newaxis]   # Cut off the first time_step to use the data as output\n",
        "\n",
        "x_weather = weather_data[:-1, :, :]\n",
        "x_terrain_expanded = np.expand_dims(terrain_data, axis=0)\n",
        "x_terrain_expanded = np.repeat(x_terrain_expanded, x_smoke.shape[0], axis=0)\n",
        "x_terrain_expanded = np.expand_dims(x_terrain_expanded, axis=1)\n",
        "x_terrain_expanded = np.repeat(x_terrain_expanded, x_smoke.shape[1], axis=1)\n",
        "\n",
        "print(f\"x_smoke shape: {x_smoke.shape}\")\n",
        "print(f\"y_smoke shape: {y_smoke.shape}\")\n",
        "print(f\"x_weather shape: {x_weather.shape}\")\n",
        "print(f\"x_terrain shape: {x_terrain_expanded.shape}\")\n",
        "\n",
        "history = model.fit(\n",
        "    x=[x_smoke, x_weather, x_terrain_expanded],\n",
        "    y=y_smoke,\n",
        "    epochs=10,\n",
        "    batch_size=4,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"Final training loss:\", history.history[\"loss\"][-1])\n",
        "print(\"Final validation loss:\", history.history[\"val_loss\"][-1])"
      ],
      "metadata": {
        "id": "LR33RO-QbG5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A hint on how to use the predict model\n",
        "\n",
        "current_smoke = smoke_data[-1:]\n",
        "current_weather = weather_data[-1:]\n",
        "current_terrain = terrain_data\n",
        "\n",
        "predicted_smoke = model.predict([current_smoke, current_weather, current_terrain])"
      ],
      "metadata": {
        "id": "3u5uCn08bMFg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}