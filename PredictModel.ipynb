{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMFTw+51WcsERgUdUwZt5bY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NancyYiWang/WildFireSmokePrediction/blob/main/PredictModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUte43UNdC7t",
        "outputId": "975a0f8c-85fd-4d2d-f5b1-23002fb3111a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import rasterio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LSTM, Dense, Flatten, TimeDistributed, Concatenate\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYWWXnnvfsvA",
        "outputId": "f1ba8ed4-7b49-4654-f89c-ac26eeec035e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.12.14)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build training data from GOES .nc files\n",
        "\n",
        "goes_dir = \"/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001\"\n",
        "smoke_output_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\"\n",
        "temp_output_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\"\n",
        "\n",
        "smoke_variables = [\n",
        "    \"MVFR_Fog_Prob\",\n",
        "    \"IFR_Fog_Prob\",\n",
        "    \"LIFR_Fog_Prob\",\n",
        "    \"Fog_Depth\",\n",
        "]\n",
        "temp_variables = [\n",
        "    \"Sfc_Temp_Bias\",\n",
        "]\n",
        "\n",
        "def extract_timestamp_from_filename(filename):\n",
        "\n",
        "    try:\n",
        "        timestamp = filename.split('_s')[1][:12]\n",
        "        return timestamp\n",
        "    except IndexError:\n",
        "        print(f\"Error extracting timestamp from {filename}\")\n",
        "        return None\n",
        "\n",
        "def filter_first_file_per_hour(nc_files):\n",
        "\n",
        "    hourly_files = {}\n",
        "    for nc_file in nc_files:\n",
        "        timestamp = extract_timestamp_from_filename(nc_file)\n",
        "        if not timestamp:\n",
        "            continue\n",
        "        hour = timestamp[8:10]\n",
        "        if hour not in hourly_files:\n",
        "            hourly_files[hour] = nc_file\n",
        "    return list(hourly_files.values())\n",
        "\n",
        "def process_goes_files(file_list, variables):\n",
        "\n",
        "    datasets = []\n",
        "    for file in file_list:\n",
        "        try:\n",
        "            with xr.open_dataset(file) as ds:\n",
        "                selected_vars = {var: ds[var].load() for var in variables if var in ds.variables}\n",
        "                if selected_vars:\n",
        "                    datasets.append(xr.Dataset(selected_vars))\n",
        "                else:\n",
        "                    print(f\"Warning: No matching variables found in {file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file}: {e}\")\n",
        "\n",
        "    if not datasets:\n",
        "        raise ValueError(\"No datasets were created. Please check the file list and variables.\")\n",
        "\n",
        "    combined_dataset = xr.concat(datasets, dim=\"time\")\n",
        "    return combined_dataset\n",
        "\n",
        "def main():\n",
        "\n",
        "    all_files = sorted([f for f in os.listdir(goes_dir) if f.endswith(\".nc\")])\n",
        "\n",
        "    selected_files = filter_first_file_per_hour(all_files)\n",
        "    selected_files = [os.path.join(goes_dir, f) for f in selected_files]\n",
        "    print(f\"GOES files to be used: {selected_files}\")\n",
        "\n",
        "    smoke_data = process_goes_files(selected_files, smoke_variables)\n",
        "    smoke_data.to_netcdf(smoke_output_file)\n",
        "    print(f\"Smoke-related data has been saved to: {smoke_output_file}\")\n",
        "\n",
        "    temp_data = process_goes_files(selected_files, temp_variables)\n",
        "    temp_data.to_netcdf(temp_output_file)\n",
        "    print(f\"Temperature-related data has been saved to: {temp_output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkwelbVlf4Yj",
        "outputId": "edb86866-0dc9-4397-b011-8b42d26dcc58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOES files to be used: ['/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010001179_e202406010003552_c202406010005019.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010101179_e202406010103552_c202406010104599.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010201180_e202406010203553_c202406010204482.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010301180_e202406010303553_c202406010304596.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010401180_e202406010403553_c202406010404397.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010501180_e202406010503553_c202406010504465.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010601180_e202406010603553_c202406010605063.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010701180_e202406010703553_c202406010704577.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010801180_e202406010803553_c202406010804449.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406010901180_e202406010903553_c202406010904586.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011001180_e202406011003553_c202406011004398.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011101180_e202406011103553_c202406011104571.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011201181_e202406011203553_c202406011205051.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011301181_e202406011303554_c202406011304478.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011401181_e202406011403554_c202406011404586.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011501181_e202406011503554_c202406011504433.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011601181_e202406011603554_c202406011604419.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011701181_e202406011703554_c202406011704572.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011801181_e202406011803554_c202406011805035.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406011901181_e202406011903554_c202406011904541.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012001181_e202406012003554_c202406012004503.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012101181_e202406012103554_c202406012104439.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012201182_e202406012203554_c202406012204452.nc', '/content/drive/My Drive/WildFire/DATA/NOAA_GOES_R/001/ABI-L2-GFLSC-M6_v3r1_g18_s202406012301182_e202406012303555_c202406012304417.nc']\n",
            "Smoke-related data has been saved to: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\n",
            "Temperature-related data has been saved to: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_nc_file(nc_file):\n",
        "\n",
        "    with xr.open_dataset(nc_file) as ds:\n",
        "        print(f\"Inspecting file: {nc_file}\")\n",
        "        print(\"\\nVariables and Dimensions:\")\n",
        "        for var in ds.variables:\n",
        "            print(f\"{var}: {ds[var].dims} {ds[var].shape}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "inspect_nc_file(smoke_output_file)\n",
        "inspect_nc_file(temp_output_file)\n",
        "\n",
        "def inspect_lat_lon_ranges(nc_file):\n",
        "    with xr.open_dataset(nc_file) as ds:\n",
        "        lat = ds['Latitude'].values\n",
        "        lon = ds['Longitude'].values\n",
        "        lat_min, lat_max = lat.min(), lat.max()\n",
        "        lon_min, lon_max = lon.min(), lon.max()\n",
        "\n",
        "    print(f\"File: {nc_file}\")\n",
        "    print(f\"Latitude range: {lat_min} to {lat_max}\")\n",
        "    print(f\"Longitude range: {lon_min} to {lon_max}\\n\")\n",
        "\n",
        "inspect_lat_lon_ranges(smoke_output_file)\n",
        "inspect_lat_lon_ranges(temp_output_file)"
      ],
      "metadata": {
        "id": "uQ36xNgb0mmL",
        "outputId": "0ef8df6d-bf14-4516-a015-fee39515bf34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting file: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\n",
            "\n",
            "Variables and Dimensions:\n",
            "Latitude: ('Rows', 'Columns') (1500, 2500)\n",
            "Longitude: ('Rows', 'Columns') (1500, 2500)\n",
            "MVFR_Fog_Prob: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "IFR_Fog_Prob: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "LIFR_Fog_Prob: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "Fog_Depth: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "\n",
            "\n",
            "Inspecting file: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\n",
            "\n",
            "Variables and Dimensions:\n",
            "Latitude: ('Rows', 'Columns') (1500, 2500)\n",
            "Longitude: ('Rows', 'Columns') (1500, 2500)\n",
            "Sfc_Temp_Bias: ('time', 'Rows', 'Columns') (24, 1500, 2500)\n",
            "\n",
            "\n",
            "File: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\n",
            "Latitude range: 14.571340560913086 to 53.500064849853516\n",
            "Longitude range: -179.999267578125 to 179.99940490722656\n",
            "\n",
            "File: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\n",
            "Latitude range: 14.571340560913086 to 53.500064849853516\n",
            "Longitude range: -179.999267578125 to 179.99940490722656\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_index_from_lat_lon(ds, lat_range, lon_range):\n",
        "\n",
        "    lat = ds['Latitude'].values\n",
        "    lon = ds['Longitude'].values\n",
        "\n",
        "    row_start = np.argmin(np.abs(lat[:, 0] - lat_range[1]))\n",
        "    row_end = np.argmin(np.abs(lat[:, 0] - lat_range[0]))\n",
        "\n",
        "    col_start = np.argmin(np.abs(lon[0, :] - lon_range[0]))\n",
        "    col_end = np.argmin(np.abs(lon[0, :] - lon_range[1]))\n",
        "\n",
        "    return slice(row_start, row_end + 1), slice(col_start, col_end + 1)\n",
        "\n",
        "\n",
        "def subset_nc_file(nc_file, lat_range, lon_range):\n",
        "\n",
        "    with xr.open_dataset(nc_file) as ds:\n",
        "        row_slice, col_slice = get_index_from_lat_lon(ds, lat_range, lon_range)\n",
        "        print(f\"Row slice: {row_slice.start} to {row_slice.stop - 1}\")\n",
        "        print(f\"Column slice: {col_slice.start} to {col_slice.stop - 1}\")\n",
        "\n",
        "        ds_subset = ds.isel(Rows=row_slice, Columns=col_slice)\n",
        "        return ds_subset\n",
        "\n",
        "lat_range = [49.5, 52.5]\n",
        "lon_range = [-116.0, -112.0]\n",
        "\n",
        "smoke_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke.nc\"\n",
        "temp_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp.nc\"\n",
        "\n",
        "smoke_data_subset = subset_nc_file(smoke_file, lat_range, lon_range)\n",
        "print(f\"Subsetted smoke data dimensions:\\n{smoke_data_subset.dims}\\n\")\n",
        "\n",
        "temp_data_subset = subset_nc_file(temp_file, lat_range, lon_range)\n",
        "print(f\"Subsetted temperature data dimensions:\\n{temp_data_subset.dims}\\n\")\n",
        "\n",
        "output_smoke_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke_subset.nc\"\n",
        "output_temp_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp_subset.nc\"\n",
        "\n",
        "smoke_data_subset.to_netcdf(output_smoke_file)\n",
        "print(f\"Subsetted smoke data saved to: {output_smoke_file}\")\n",
        "\n",
        "temp_data_subset.to_netcdf(output_temp_file)\n",
        "print(f\"Subsetted temperature data saved to: {output_temp_file}\")"
      ],
      "metadata": {
        "id": "1H0k5oc51h2E",
        "outputId": "20be74c7-d2d0-4c85-adba-959f374b037f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row slice: 22 to 94\n",
            "Column slice: 1909 to 2021\n",
            "Subsetted smoke data dimensions:\n",
            "FrozenMappingWarningOnValuesAccess({'Rows': 73, 'Columns': 113, 'time': 24})\n",
            "\n",
            "Row slice: 22 to 94\n",
            "Column slice: 1909 to 2021\n",
            "Subsetted temperature data dimensions:\n",
            "FrozenMappingWarningOnValuesAccess({'Rows': 73, 'Columns': 113, 'time': 24})\n",
            "\n",
            "Subsetted smoke data saved to: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke_subset.nc\n",
            "Subsetted temperature data saved to: /content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp_subset.nc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weather_data(nc_files, time_steps):\n",
        "    weather_features = []\n",
        "    for file in nc_files:\n",
        "        with xr.open_dataset(file) as ds:\n",
        "            feature = ds.to_array().values[:time_steps]\n",
        "            weather_features.append(feature)\n",
        "    return np.stack(weather_features, axis=-1)\n",
        "\n",
        "\n",
        "def load_terrain_data(terrain_file, downscale_factor=4):\n",
        "    with rasterio.open(terrain_file) as src:\n",
        "        terrain = src.read(\n",
        "            1, out_shape=(\n",
        "                int(src.height // downscale_factor),\n",
        "                int(src.width // downscale_factor)\n",
        "            )\n",
        "        )\n",
        "    return terrain / np.max(terrain)\n",
        "\n",
        "def load_smoke_and_temp(smoke_file, temp_file):\n",
        "\n",
        "    with xr.open_dataset(smoke_file) as smoke_ds:\n",
        "        smoke_data = smoke_ds.to_array().values\n",
        "\n",
        "    with xr.open_dataset(temp_file) as temp_ds:\n",
        "        temp_data = temp_ds.to_array().values\n",
        "\n",
        "    time_ids = np.arange(1967184, 1967208)\n",
        "\n",
        "    return smoke_data, temp_data, time_ids\n",
        "\n",
        "def build_model(input_shape_smoke, input_shape_weather, input_shape_terrain):\n",
        "\n",
        "    # Input for smoke data (CNN)\n",
        "    smoke_input = Input(shape=input_shape_smoke, name=\"Smoke_Input\")\n",
        "    x = TimeDistributed(Conv2D(4, (3, 3), activation=\"relu\", padding=\"same\"))(smoke_input)\n",
        "    x = TimeDistributed(Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\"))(x)\n",
        "    x = TimeDistributed(Flatten())(x)  # Shape: (time_steps, flattened_features)\n",
        "\n",
        "    # Input for weather data (LSTM)\n",
        "    weather_input = Input(shape=input_shape_weather, name=\"Weather_Input\")\n",
        "    w = LSTM(16, return_sequences=True)(weather_input)\n",
        "    w = LSTM(16)(w)\n",
        "\n",
        "    # Input for terrain data (Dense)\n",
        "    terrain_input = Input(shape=input_shape_terrain, name=\"Terrain_Input\")\n",
        "    t = Dense(64, activation=\"relu\")(terrain_input)  # Shape: (64,)\n",
        "\n",
        "    # Combine all inputs\n",
        "    combined = Concatenate()([Flatten()(x), w, t])  # Shape: (combined_features,)\n",
        "\n",
        "    # Output layer\n",
        "    output_size = input_shape_smoke[1] * input_shape_smoke[2]  # Height * Width\n",
        "    out = Dense(output_size, activation=\"sigmoid\")(combined)  # Flattened output\n",
        "    out = tf.keras.layers.Reshape(target_shape=input_shape_smoke[1:])(out)  # Reshape to (height, width, channels)\n",
        "\n",
        "    # Define model\n",
        "    model = Model(inputs=[smoke_input, weather_input, terrain_input], outputs=out)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KCGOXEiOVddU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File Directories\n",
        "nc_files = [\"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/vwnd.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/air.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/hgt.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/omega.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/rhum.2024.nc\",\n",
        "            \"/content/drive/My Drive/WildFire/DATA/NOAA_Climate/uwnd.2024.nc\"]\n",
        "terrain_file = \"/content/drive/My Drive/WildFire/DATA/Terrain/terrain_broad_calgary.tiff\"\n",
        "smoke_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_smoke_subset.nc\"\n",
        "temp_file = \"/content/drive/My Drive/WildFire/DATA/Processed/GOES_20240601_temp_subset.nc\"\n",
        "\n",
        "# Processing files\n",
        "\n",
        "start_time = \"2024-06-01T00:00:00\"\n",
        "end_time = \"2024-06-01T23:00:00\"\n",
        "\n",
        "weather_data = load_weather_data(nc_files, start_time, end_time)\n",
        "terrain_data = load_terrain_data(terrain_file)\n",
        "smoke_data, temp_data, time_ids = load_smoke_and_temp(smoke_file, temp_file)\n",
        "\n",
        "# Define input datashape\n",
        "time_steps = smoke_data.shape[0]\n",
        "input_shape_smoke = (time_steps, smoke_data.shape[1], smoke_data.shape[2], 1)\n",
        "input_shape_weather = (time_steps, weather_data.shape[-1])\n",
        "input_shape_terrain = (terrain_data.size,)\n",
        "\n",
        "# Train model\n",
        "model = build_model(input_shape_smoke, input_shape_weather, input_shape_terrain)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "x_smoke = smoke_data[:, :-1, :, :, np.newaxis]  # Cut off the last time_step to use the data as input\n",
        "y_smoke = smoke_data[:, 1:, :, :, np.newaxis]   # Cut off the first time_step to use the data as output\n",
        "\n",
        "x_weather = weather_data[:-1]\n",
        "x_terrain = terrain_data\n",
        "\n",
        "print(f\"x_smoke shape: {x_smoke.shape}\")\n",
        "print(f\"y_smoke shape: {y_smoke.shape}\")\n",
        "print(f\"x_weather shape: {x_weather.shape}\")\n",
        "print(f\"x_terrain shape: {x_terrain.shape}\")\n",
        "\n",
        "history = model.fit(\n",
        "    x=[x_smoke, x_weather, x_terrain],\n",
        "    y=y_smoke,\n",
        "    epochs=10,\n",
        "    batch_size=4,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"Final training loss:\", history.history[\"loss\"][-1])\n",
        "print(\"Final validation loss:\", history.history[\"val_loss\"][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "LR33RO-QbG5v",
        "outputId": "9ae8c734-0c55-42ab-9c38-6cde04d79010"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_smoke shape: (4, 23, 73, 113, 1)\n",
            "y_smoke shape: (4, 23, 73, 113, 1)\n",
            "x_weather shape: (0, 4, 17, 73, 144, 6)\n",
            "x_terrain shape: (180, 240)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 3, 0, 3\n'y' sizes: 3\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-277cb68ba662>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"x_terrain shape: {x_terrain.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_smoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_weather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_terrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_smoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n\u001b[1;32m    113\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 3, 0, 3\n'y' sizes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A hint on how to use the predict model\n",
        "\n",
        "current_smoke = smoke_data[-1:]\n",
        "current_weather = weather_data[-1:]\n",
        "current_terrain = terrain_data\n",
        "\n",
        "predicted_smoke = model.predict([current_smoke, current_weather, current_terrain])"
      ],
      "metadata": {
        "id": "3u5uCn08bMFg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}